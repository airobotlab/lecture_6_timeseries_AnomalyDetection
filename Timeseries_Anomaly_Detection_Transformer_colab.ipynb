{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIUJpUseKDOp"
      },
      "source": [
        "# Time-series Anomaly Detection. transformer&gru model with HAI\n",
        "\n",
        "220517\n",
        "\n",
        "[URL](https://dacon.io/competitions/official/235757/codeshare/3086?page=2&dtype=recent)\n",
        "\n",
        "GRU, pytorch code"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 선택!\n",
        "\n",
        "- 1) Trnaformer\n",
        "- 2) GRU"
      ],
      "metadata": {
        "id": "OrRCuE_fKaUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# config\n",
        "model_type = 'transformer'\n",
        "# model_type = 'gru'\n"
      ],
      "metadata": {
        "id": "YnVz_lFbKZkU"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pf_Ur4A6KDOr"
      },
      "source": [
        "# 0_데이터 준비\n",
        "\n",
        "- 1) 아래 URL에서 데이터를 다운로드\n",
        "- 2) 235757_HAICon2021_dataset.zip 파일을 colab에 upload, 그런데 너무 오래걸려요! 이번엔 구글 드라이브에 연동해 봅시다\n",
        "\n",
        "- 3) 구글 드라이브에 다운받은 235757_HAICon2021_dataset.zip 파일을 업로드 후 아래 코드를 실행\n",
        "\n",
        "- [DATA DOWNLOAD URL](https://dacon.io/competitions/official/235757/data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1EMX7jszKDOs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cd48998-b998-484f-f051-352d55e1a2a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# 구글 드라이브 colab과 연동\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "He-uUMpeKDOt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d44d9c08-7e49-47bb-adac-e5ff9b48ca39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 0000.zip  '200924_축의금 목록.xlsx'\t   'My Drive'\n",
            " 000.zip    235757_HAICon2021_dataset.zip   YOLOv5_test\n",
            " 0.zip\t   'Colab Notebooks'\t\t   '강아지 그림 사진.zip'\n"
          ]
        }
      ],
      "source": [
        "# MyDrive 폴더 안에 235757_HAICon2021_dataset.zip 파일이 잘 업로드 되어있나요?\n",
        "!ls /content/drive/MyDrive/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ddUhH1wKKDOu"
      },
      "outputs": [],
      "source": [
        "# 그럼 이 코드로 colab으로 가져옵니다. 엄청 빠릅니다.\n",
        "!cp /content/drive/MyDrive/235757_HAICon2021_dataset.zip ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4fpGqCotKDOu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc3f5470-5d70-4e87-e7a2-f70564cd1e1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data\n",
            "Archive:  ./235757_HAICon2021_dataset.zip\n",
            "  inflating: eTaPR-21.8.2-py3-none-any.whl  \n",
            "  inflating: sample_submission.csv   \n",
            "   creating: test/\n",
            "  inflating: test/test1.csv          \n",
            "  inflating: test/test2.csv          \n",
            "  inflating: test/test3.csv          \n",
            "   creating: train/\n",
            "  inflating: train/train1.csv        \n",
            "  inflating: train/train2.csv        \n",
            "  inflating: train/train3.csv        \n",
            "  inflating: train/train4.csv        \n",
            "  inflating: train/train5.csv        \n",
            "  inflating: train/train6.csv        \n",
            "   creating: validation/\n",
            "  inflating: validation/validation.csv  \n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "# data 폴더를 만든 후 그 안에 압축을 풉시다\n",
        "import os\n",
        "# 파일이 이미 있으면 pass\n",
        "if not os.path.exists('data/train'):\n",
        "    !mkdir ./data\n",
        "    !mv 235757_HAICon2021_dataset.zip ./data/\n",
        "    %cd ./data\n",
        "    !unzip ./235757_HAICon2021_dataset.zip\n",
        "    %cd ..\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OObx7GZgKDOu"
      },
      "source": [
        "## model_type을 transformer나 gru 중 고를 수 있다!\n",
        "### 어떤 모델이 더 빠르고 성능이 좋은가요??"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "code_folding": [],
        "id": "CiQTlkjFKDOv"
      },
      "outputs": [],
      "source": [
        "if model_type == 'gru':\n",
        "    batch_size = 4096\n",
        "    epochs = 100  # 20min\n",
        "elif model_type == 'transformer':\n",
        "    batch_size = 512\n",
        "    epochs = 20  # 1hour\n",
        "\n",
        "device = 'cuda'\n",
        "WINDOW_SIZE = 90  # 89개의 데이터를 보고 다음 한개를 예측\n",
        "stride = 10  # 데이터 슬라이딩 크기, 1등은 1로 뒀음\n",
        "# ready = True  # 미리 데이터 처리를 해놓으면 True\n",
        "ready = False  # 미리 데이터 처리를 해놓으면 True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "code_folding": [
          0
        ],
        "id": "Uz774ldWKDOv",
        "outputId": "e94b57c2-d4f2-41f3-eeaf-e72c0ca37d12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ./data/eTaPR-21.8.2-py3-none-any.whl\n",
            "eTaPR is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
            "Collecting watermark\n",
            "  Downloading watermark-2.3.0-py2.py3-none-any.whl (7.2 kB)\n",
            "Collecting importlib-metadata<3.0\n",
            "  Downloading importlib_metadata-2.1.3-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from watermark) (5.5.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<3.0->watermark) (3.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->watermark) (1.0.18)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->watermark) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->watermark) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->watermark) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->watermark) (57.4.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->watermark) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->watermark) (5.1.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->watermark) (2.6.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->watermark) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->watermark) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->watermark) (0.7.0)\n",
            "Installing collected packages: importlib-metadata, watermark\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.11.3\n",
            "    Uninstalling importlib-metadata-4.11.3:\n",
            "      Successfully uninstalled importlib-metadata-4.11.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "markdown 3.3.6 requires importlib-metadata>=4.4; python_version < \"3.10\", but you have importlib-metadata 2.1.3 which is incompatible.\u001b[0m\n",
            "Successfully installed importlib-metadata-2.1.3 watermark-2.3.0\n",
            "Python implementation: CPython\n",
            "Python version       : 3.7.13\n",
            "IPython version      : 5.5.0\n",
            "\n",
            "dateutil  : 2.8.2\n",
            "numpy     : 1.21.6\n",
            "matplotlib: 3.2.2\n",
            "pandas    : 1.3.5\n",
            "torch     : 1.11.0+cu113\n",
            "tqdm      : 4.64.0\n",
            "TaPR_pkg  : unknown\n",
            "cv2       : 4.1.2\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## setup\n",
        "!python -m pip install data/eTaPR-21.8.2-py3-none-any.whl  # TaPR은 평가 metric 설치\n",
        "!pip install watermark \n",
        "%reload_ext watermark\n",
        "%watermark -v -p dateutil,numpy,matplotlib,pandas,torch,tqdm,TaPR_pkg,cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "code_folding": [
          0
        ],
        "id": "tP9bzEWqKDOw"
      },
      "outputs": [],
      "source": [
        "# import\n",
        "import sys\n",
        "import os\n",
        "import random\n",
        "from pathlib import Path\n",
        "from datetime import timedelta\n",
        "\n",
        "import dateutil\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm.notebook import trange\n",
        "from TaPR_pkg import etapr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "code_folding": [
          0
        ],
        "id": "di8-2Sb_KDOw",
        "outputId": "749a5d58-4f37-4307-b8fb-4ad31a143b90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "# 사용할 GPU 설정\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" # PCI_BUS_ID 기준으로 control하겠다는 의미인듯.\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" # [number]는 GPU 번호. (복수도 가능 ex. \"1,2\")\n",
        "print(torch.cuda.is_available())\n",
        "\n",
        "# seed 고정을 위한 함수 정의\n",
        "def seed_everything(seed = 777):\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "seed_everything()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpHkTqhyKDOx"
      },
      "source": [
        "## 1_데이터 전처리\n",
        "\n",
        "학습 데이터와 테스트 데이터는 CSV로 제공됩니다.\n",
        "HAI 2.0은 단일 파일이 아니라 여러 파일로 제공되기 때문에 디렉토리 안에 있는 모든 CSV를 읽습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "code_folding": [
          0
        ],
        "id": "aaxt6dGtKDOx"
      },
      "outputs": [],
      "source": [
        "## data process functions\n",
        "def dataframe_from_csv(target):\n",
        "    return pd.read_csv(target).rename(columns=lambda x: x.strip())\n",
        "\n",
        "def dataframe_from_csvs(targets):\n",
        "    return pd.concat([dataframe_from_csv(x) for x in targets])\n",
        "\n",
        "def normalize(df):\n",
        "    ndf = df.copy()\n",
        "    for c in df.columns:\n",
        "        if TAG_MIN[c] == TAG_MAX[c]:\n",
        "            ndf[c] = df[c] - TAG_MIN[c]\n",
        "        else:\n",
        "            ndf[c] = (df[c] - TAG_MIN[c]) / (TAG_MAX[c] - TAG_MIN[c])\n",
        "    return ndf\n",
        "\n",
        "def boundary_check(df):\n",
        "    x = np.array(df, dtype=np.float32)\n",
        "    return np.any(x > 1.0), np.any(x < 0), np.any(np.isnan(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "code_folding": [
          9
        ],
        "id": "8SfZV0VfKDOx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6e50738-9a13-4433-b4bc-82a36ffd42b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PosixPath('data/train/train1.csv'), PosixPath('data/train/train2.csv'), PosixPath('data/train/train3.csv'), PosixPath('data/train/train4.csv'), PosixPath('data/train/train5.csv'), PosixPath('data/train/train6.csv')]\n",
            "[PosixPath('data/test/test1.csv'), PosixPath('data/test/test2.csv'), PosixPath('data/test/test3.csv')]\n",
            "[PosixPath('data/validation/validation.csv')]\n",
            "load & normalize complete\n",
            "train data check: (False, False, False)\n",
            "test  data check: (True, True, False)\n",
            "valid data check: (True, True, False)\n"
          ]
        }
      ],
      "source": [
        "## data processing\n",
        "\n",
        "TIMESTAMP_FIELD = \"timestamp\"\n",
        "DROP_FIELD = [\"timestamp\", \n",
        "              \"C02\", \"C03\", \"C14\", \"C18\", \"C19\", \"C21\", \"C22\", \"C25\", \"C33\", \"C34\", \"C35\", \"C37\", \"C40\", \"C43\", \"C51\", \"C52\", \"C59\", \"C61\", \"C63\", \"C64\", \"C65\", \"C67\",\n",
        "              \"C04\", \"C05\", \"C06\", \"C07\", \"C08\", \"C10\", \"C11\", \"C17\", \"C24\", \"C28\", \"C32\", \"C44\", \"C46\", \"C48\", \"C49\", \"C50\", \"C53\", \"C58\", \"C62\", \"C71\", \"C76\", \"C78\", \"C79\"]\n",
        "IDSTAMP_FIELD = 'id'\n",
        "ATTACK_FIELD = \"attack\"\n",
        "    \n",
        "if not ready:\n",
        "    TRAIN_DATASET = sorted([x for x in Path(\"data/train/\").glob(\"*.csv\")])\n",
        "    TEST_DATASET = sorted([x for x in Path(\"data/test/\").glob(\"*.csv\")])\n",
        "    VALIDATION_DATASET = sorted([x for x in Path(\"data/validation/\").glob(\"*.csv\")])\n",
        "    print(TRAIN_DATASET)\n",
        "    print(TEST_DATASET)\n",
        "    print(VALIDATION_DATASET)\n",
        "\n",
        "    TRAIN_DF_RAW = dataframe_from_csvs(TRAIN_DATASET)\n",
        "    TEST_DF_RAW = dataframe_from_csvs(TEST_DATASET)\n",
        "    VALIDATION_DF_RAW = dataframe_from_csvs(VALIDATION_DATASET)\n",
        "\n",
        "    VALID_COLUMNS_IN_TRAIN_DATASET = TRAIN_DF_RAW.columns.drop(DROP_FIELD) # DROP_FIELD를 통해 normalization에 사용하지 않을 변수를 제거함.\n",
        "    TAG_MIN = TRAIN_DF_RAW[VALID_COLUMNS_IN_TRAIN_DATASET].min()  # 각 열의 최소값\n",
        "    TAG_MAX = TRAIN_DF_RAW[VALID_COLUMNS_IN_TRAIN_DATASET].max()  # 각 열의 최대값\n",
        "\n",
        "    # 각 필드가 가지는 값의 범위가 다르므로 정규화, Min-Max Normalize(0~1)\n",
        "    # 정규화 후 exponential weighted function를 통과시켜 센서에서 발생하는 noise를 smoothing\n",
        "    TRAIN_DF = normalize(TRAIN_DF_RAW[VALID_COLUMNS_IN_TRAIN_DATASET]).ewm(alpha=0.9).mean()\n",
        "    VALIDATION_DF = normalize(VALIDATION_DF_RAW[VALID_COLUMNS_IN_TRAIN_DATASET])\n",
        "    TEST_DF = normalize(TEST_DF_RAW[VALID_COLUMNS_IN_TRAIN_DATASET]).ewm(alpha=0.9).mean()\n",
        "    print('load & normalize complete')\n",
        "\n",
        "    # Boundary Check, 데이터 중 0~1이 아닌 값이 있는지 체크.1 초과/0 미만/NaN\n",
        "    print('train data check:', boundary_check(TRAIN_DF))\n",
        "    print('test  data check:', boundary_check(TEST_DF))\n",
        "    print('valid data check:', boundary_check(VALIDATION_DF))  # 공격 데이터셋에서는 확실히 정상 데이터의 최솟값과 최댓값을 벗어나는 값이 나타남"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rU_VTpONKDOy"
      },
      "source": [
        "## 2_데이터 입출력 정의\n",
        "\n",
        "- 베이스라인 모델은 Stacked RNN(GRU cells)을 이용해서 이상을 탐지\n",
        "- 정상 데이터로 학습, label이 없으므로 unsupervised learning\n",
        "- 슬라이딩 윈도우를 통해 시계열 데이터의 일부를 가져와서 해당 윈도우의 패턴을 기억\n",
        "- 슬라이딩 윈도우는 90초(HAI는 1초마다 샘플링되어 있습니다)로 설정했습니다.\n",
        "\n",
        "- 모델의 입출력\n",
        "    - 입력 : 윈도우의 앞부분 89초에 해당하는 값\n",
        "    - 출력 : 윈도우의 가장 마지막 초(90번째 초)의 값\n",
        "\n",
        "- inference 시 모델이 출력하는 값(예측값)과 실제로 들어온 값의 차이가 크면 이상으로 간주\n",
        "- 오차가 크면 학습 데이터셋에서 본 적이 없는 패턴"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "code_folding": [
          0,
          1
        ],
        "id": "FDqduIxeKDO2",
        "outputId": "d0143770-7f0f-4ed0-c652-3563a76137ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412,
          "referenced_widgets": [
            "39014eae9e4049db97108ba1b4fda192",
            "f76e4243c59a475996199d9b2c507439",
            "f08672a400fa4504a92a71b0e04de914",
            "bc2a9fe91e304c72a394ac2592a58115",
            "71f44c75b7c64ee7aba3c5f8dbd9ec28",
            "1aee9ab1cc5c4049820bcc39500129b6",
            "8853b2ba36ee415a8d77a6291465dc21",
            "8df8722607c34b458dfac93b19ab5b1e",
            "05d9f80811cc4b1ea65511da79085114",
            "0aba92e4fc634ecb8b0589aec8207b9b",
            "b82bdc93b05546548a6ad9b97778a413",
            "1bf774806ae2426289c48990c02d5e78",
            "bf00b2f646cb4782ba97e06aaba39c01",
            "672ff02a463c4175b1d6d502f1ac0359",
            "9f71b8fcf1084ddf9e3afb8c9bb97ecb",
            "7f07539d85174051a06b2008f975cc08",
            "28230cba99d5460788564eec3933c834",
            "174d06a91040448f85a618eb9608b799",
            "34160db8fca04a88bbdda12c9070d315",
            "7abd9f5ec69049c7a056626846cd65a7",
            "e6d07f190965493c9240936491f2c900",
            "29aeddc801a347d7959763a6ae6a95b3",
            "ad5d5cddacd4494da179f1692018de3d",
            "6eec3560d9a042c6807e2b5beb471314",
            "34a47072f70e4a55b1e0f0899d931075",
            "60cb0565162f41d8982ac73be9c95b6d",
            "465813650760485481e629babf6b34b3",
            "8573d07596c84c9680ac3cae6b381519",
            "339b65949b874f9a91c33f8ab168191a",
            "109eda945e0742dba2406cfea225a5dd",
            "964ec628a78b47738afada32617fdec8",
            "d7951da553a84daf999fc2a0058fea32",
            "586ec79202b4450c814d8493e8d3c079"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1004313 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "39014eae9e4049db97108ba1b4fda192"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of valid windows: 100387\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/86311 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1bf774806ae2426289c48990c02d5e78"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of valid windows: 86311\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/274711 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ad5d5cddacd4494da179f1692018de3d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of valid windows: 274533\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': tensor([0.3711, 0.0000, 0.6224, 0.4866, 0.2524, 0.2907, 0.3050, 0.3492, 0.0000,\n",
              "         0.3563, 0.0000, 0.9763, 0.5501, 0.0000, 0.0000, 0.0000, 0.2642, 0.5416,\n",
              "         0.0021, 0.5253, 0.0509, 0.0000, 0.3105, 0.7985, 0.4340, 0.2261, 0.2123,\n",
              "         0.0000, 0.4706, 0.1565, 0.4803, 0.1081, 0.2816, 0.2480, 0.1132, 0.5313,\n",
              "         0.0000, 0.5381, 0.0000, 0.0000, 0.0091]),\n",
              " 'given': tensor([[0.4331, 0.0000, 0.5019,  ..., 0.0000, 0.0000, 0.2761],\n",
              "         [0.3951, 0.0000, 0.5021,  ..., 0.0000, 0.0000, 0.2752],\n",
              "         [0.3333, 0.0000, 0.5021,  ..., 0.0000, 0.0000, 0.2749],\n",
              "         ...,\n",
              "         [0.3205, 0.0000, 0.6222,  ..., 0.0000, 0.0000, 0.0091],\n",
              "         [0.4451, 0.0000, 0.6222,  ..., 0.0000, 0.0000, 0.0091],\n",
              "         [0.3477, 0.0000, 0.6222,  ..., 0.0000, 0.0000, 0.0091]]),\n",
              " 'ts': '2021-07-11 10:01:29'}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "#### dataset 선언, 2min\n",
        "class HaiDataset(Dataset):\n",
        "    def __init__(self, timestamps, df, WINDOW_SIZE=90, stride=1, attacks=None):\n",
        "        self.ts = np.array(timestamps)\n",
        "        self.tag_values = np.array(df, dtype=np.float32)\n",
        "        self.valid_idxs = []\n",
        "        self.WINDOW_SIZE = WINDOW_SIZE\n",
        "        \n",
        "        for L in trange(len(self.ts) - self.WINDOW_SIZE + 1):\n",
        "            R = L + self.WINDOW_SIZE - 1\n",
        "            if dateutil.parser.parse(self.ts[R]) - dateutil.parser.parse(\n",
        "                self.ts[L]\n",
        "            ) == timedelta(seconds=self.WINDOW_SIZE - 1):\n",
        "                self.valid_idxs.append(L)\n",
        "        self.valid_idxs = np.array(self.valid_idxs, dtype=np.int32)[::stride]\n",
        "        self.n_idxs = len(self.valid_idxs)\n",
        "        print(f\"# of valid windows: {self.n_idxs}\")\n",
        "        if attacks is not None:\n",
        "            self.attacks = np.array(attacks, dtype=np.float32)\n",
        "            self.with_attack = True\n",
        "        else:\n",
        "            self.with_attack = False\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_idxs\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        i = self.valid_idxs[idx]\n",
        "        last = i + self.WINDOW_SIZE - 1\n",
        "        item = {\"attack\": self.attacks[last]} if self.with_attack else {}\n",
        "        item[\"ts\"] = self.ts[i + self.WINDOW_SIZE - 1]\n",
        "        item[\"given\"] = torch.from_numpy(self.tag_values[i : i + self.WINDOW_SIZE - 1])\n",
        "        item[\"answer\"] = torch.from_numpy(self.tag_values[last])\n",
        "        return item\n",
        "\n",
        "if not ready:\n",
        "    HAI_DATASET_TRAIN = HaiDataset(TRAIN_DF_RAW[TIMESTAMP_FIELD], TRAIN_DF, WINDOW_SIZE=WINDOW_SIZE, stride=stride)\n",
        "    # 모든 데이터 포인트에 대해 점검해야 하므로 validation/test 데이터의 stride 크기는 1\n",
        "    HAI_DATASET_VALIDATION = HaiDataset(VALIDATION_DF_RAW[TIMESTAMP_FIELD], VALIDATION_DF, WINDOW_SIZE=WINDOW_SIZE, stride=1, attacks=VALIDATION_DF_RAW[ATTACK_FIELD])\n",
        "    HAI_DATASET_TEST = HaiDataset(TEST_DF_RAW[TIMESTAMP_FIELD], TEST_DF, WINDOW_SIZE=WINDOW_SIZE, stride=1, attacks=None)\n",
        "\n",
        "    with open('data.pickle', 'wb') as f:\n",
        "        pickle.dump([HAI_DATASET_TRAIN, HAI_DATASET_VALIDATION, HAI_DATASET_TEST, TRAIN_DF, VALIDATION_DF, TEST_DF, TRAIN_DF_RAW, TEST_DF_RAW, VALIDATION_DF_RAW], f, pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# load\n",
        "with open('data.pickle', 'rb') as f:\n",
        "    [HAI_DATASET_TRAIN, HAI_DATASET_VALIDATION, HAI_DATASET_TEST, TRAIN_DF, VALIDATION_DF, TEST_DF, TRAIN_DF_RAW, TEST_DF_RAW, VALIDATION_DF_RAW] = pickle.load(f)\n",
        "    \n",
        "HAI_DATASET_TRAIN[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VsxeYpzKDO3"
      },
      "source": [
        "## 3_define model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "code_folding": [
          0
        ],
        "id": "LaXtH-VyKDO3"
      },
      "outputs": [],
      "source": [
        "# 3.1. define GRU model\n",
        "\n",
        "if model_type == 'gru':\n",
        "    N_HIDDENS = 100  # Hidden cell\n",
        "    N_LAYERS = 3  # 3층 bidirectional GRU\n",
        "\n",
        "    class StackedGRU(torch.nn.Module):\n",
        "        def __init__(self, n_tags):\n",
        "            super().__init__()\n",
        "            self.rnn = torch.nn.GRU(\n",
        "                input_size=n_tags,\n",
        "                hidden_size=N_HIDDENS,\n",
        "                num_layers=N_LAYERS,\n",
        "                bidirectional=True,\n",
        "                dropout=0,\n",
        "            )\n",
        "            self.fc = torch.nn.Linear(N_HIDDENS * 2, n_tags)\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = x.transpose(0, 1)  # (batch, seq, params) -> (seq, batch, params)\n",
        "            self.rnn.flatten_parameters()\n",
        "            outs, _ = self.rnn(x)\n",
        "            out = self.fc(outs[-1])\n",
        "    #         out = self.fc(self.relu(outs[-1]))  # 1등 코드        \n",
        "            return x[0] + out  # 모델이 윈도우의 가장 첫 번째 값과 GRU의 출력을 더해서 내보내도록 skip connection\n",
        "\n",
        "\n",
        "    MODEL = StackedGRU(n_tags=TRAIN_DF.shape[1])\n",
        "    MODEL.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "code_folding": [
          0,
          34,
          43,
          94,
          116,
          146,
          169,
          222
        ],
        "id": "lfumbXFnKDO3"
      },
      "outputs": [],
      "source": [
        "# 3.2. define transformer model\n",
        "'''\n",
        "데이콘에서 제공한 StackedGRU가 아닌 Transformer 모델\n",
        "transformer의 경우 input sequence가 길 경우 기존 GRU에 비해 상대적으로 학습에 효율적이며 self-attention을 사용해 한번에 전체 맥락 파악\n",
        "github에 공개된 Transformer pytorch source code 사용\n",
        "encoder layer 구조만 사용했으며 기존 word_embbding 대신 linear_emb 변경\n",
        "'''\n",
        "if model_type == 'transformer':\n",
        "    \n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    import torch.nn.functional as F\n",
        "\n",
        "\n",
        "    class ScaledDotProductAttention(nn.Module):\n",
        "        ''' Scaled Dot-Product Attention '''\n",
        "        def __init__(self, temperature, attn_dropout=0.1):\n",
        "            super().__init__()\n",
        "            self.temperature = temperature\n",
        "            self.dropout = nn.Dropout(attn_dropout)\n",
        "\n",
        "        def forward(self, q, k, v, mask=None):\n",
        "\n",
        "            attn = torch.matmul(q / self.temperature, k.transpose(2, 3))\n",
        "\n",
        "            if mask is not None:\n",
        "                attn = attn.masked_fill(mask == 0, -1e9)\n",
        "\n",
        "            attn = self.dropout(F.softmax(attn, dim=-1))\n",
        "            output = torch.matmul(attn, v)\n",
        "\n",
        "            return output, attn\n",
        "\n",
        "\n",
        "    def get_subsequent_mask(seq):\n",
        "        ''' For masking out the subsequent info. '''\n",
        "        sz_b, len_s = seq.size()\n",
        "        subsequent_mask = (1 - torch.triu(torch.ones(\n",
        "            (1, len_s, len_s), device=seq.device),\n",
        "                                          diagonal=1)).bool()\n",
        "        return subsequent_mask\n",
        "\n",
        "\n",
        "    class MultiHeadAttention(nn.Module):\n",
        "        ''' Multi-Head Attention module '''\n",
        "        def __init__(self, n_head, d_model, d_k, d_v, dropout=0.1):\n",
        "            super().__init__()\n",
        "\n",
        "            self.n_head = n_head\n",
        "            self.d_k = d_k\n",
        "            self.d_v = d_v\n",
        "\n",
        "            self.w_qs = nn.Linear(d_model, n_head * d_k, bias=False)\n",
        "            self.w_ks = nn.Linear(d_model, n_head * d_k, bias=False)\n",
        "            self.w_vs = nn.Linear(d_model, n_head * d_v, bias=False)\n",
        "            self.fc = nn.Linear(n_head * d_v, d_model, bias=False)\n",
        "\n",
        "            self.attention = ScaledDotProductAttention(temperature=d_k**0.5)\n",
        "\n",
        "            self.dropout = nn.Dropout(dropout)\n",
        "            self.layer_norm = nn.LayerNorm(d_model, eps=1e-6)\n",
        "\n",
        "        def forward(self, q, k, v, mask=None):\n",
        "\n",
        "            d_k, d_v, n_head = self.d_k, self.d_v, self.n_head\n",
        "            sz_b, len_q, len_k, len_v = q.size(0), q.size(1), k.size(1), v.size(1)\n",
        "\n",
        "            residual = q\n",
        "\n",
        "            # Pass through the pre-attention projection: b x lq x (n*dv)\n",
        "            # Separate different heads: b x lq x n x dv\n",
        "            q = self.w_qs(q).view(sz_b, len_q, n_head, d_k)\n",
        "            k = self.w_ks(k).view(sz_b, len_k, n_head, d_k)\n",
        "            v = self.w_vs(v).view(sz_b, len_v, n_head, d_v)\n",
        "\n",
        "            # Transpose for attention dot product: b x n x lq x dv\n",
        "            q, k, v = q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2)\n",
        "\n",
        "            if mask is not None:\n",
        "                mask = mask.unsqueeze(1)  # For head axis broadcasting.\n",
        "\n",
        "            q, attn = self.attention(q, k, v, mask=mask)\n",
        "\n",
        "            # Transpose to move the head dimension back: b x lq x n x dv\n",
        "            # Combine the last two dimensions to concatenate all the heads together: b x lq x (n*dv)\n",
        "            q = q.transpose(1, 2).contiguous().view(sz_b, len_q, -1)\n",
        "            q = self.dropout(self.fc(q))\n",
        "            q += residual\n",
        "\n",
        "            q = self.layer_norm(q)\n",
        "\n",
        "            return q, attn\n",
        "\n",
        "\n",
        "    class PositionwiseFeedForward(nn.Module):\n",
        "        ''' A two-feed-forward-layer module '''\n",
        "        def __init__(self, d_in, d_hid, dropout=0.1):\n",
        "            super().__init__()\n",
        "            self.w_1 = nn.Linear(d_in, d_hid)  # position-wise\n",
        "            self.w_2 = nn.Linear(d_hid, d_in)  # position-wise\n",
        "            self.layer_norm = nn.LayerNorm(d_in, eps=1e-6)\n",
        "            self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        def forward(self, x):\n",
        "\n",
        "            residual = x\n",
        "\n",
        "            x = self.w_2(F.relu(self.w_1(x)))\n",
        "            x = self.dropout(x)\n",
        "            x += residual\n",
        "\n",
        "            x = self.layer_norm(x)\n",
        "\n",
        "            return x\n",
        "\n",
        "\n",
        "    class PositionalEncoding(nn.Module):\n",
        "        def __init__(self, d_hid, n_position=86):\n",
        "            super(PositionalEncoding, self).__init__()\n",
        "\n",
        "            # Not a parameter\n",
        "            self.register_buffer(\n",
        "                'pos_table', self._get_sinusoid_encoding_table(n_position, d_hid))\n",
        "\n",
        "        def _get_sinusoid_encoding_table(self, n_position, d_hid):\n",
        "            ''' Sinusoid position encoding table '''\n",
        "\n",
        "            # TODO: make it with torch instead of numpy\n",
        "\n",
        "            def get_position_angle_vec(position):\n",
        "                return [\n",
        "                    position / np.power(10000, 2 * (hid_j // 2) / d_hid)\n",
        "                    for hid_j in range(d_hid)\n",
        "                ]\n",
        "\n",
        "            sinusoid_table = np.array(\n",
        "                [get_position_angle_vec(pos_i) for pos_i in range(n_position)])\n",
        "            sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # dim 2i\n",
        "            sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # dim 2i+1\n",
        "\n",
        "            return torch.FloatTensor(sinusoid_table).unsqueeze(0)\n",
        "\n",
        "        def forward(self, x):\n",
        "            return x + self.pos_table[:, :x.size(1)].clone().detach()\n",
        "\n",
        "\n",
        "    class EncoderLayer(nn.Module):\n",
        "        ''' Compose with two layers '''\n",
        "        def __init__(self, d_model, d_inner, n_head, d_k, d_v, dropout=0.1):\n",
        "            super(EncoderLayer, self).__init__()\n",
        "            self.slf_attn = MultiHeadAttention(n_head,\n",
        "                                               d_model,\n",
        "                                               d_k,\n",
        "                                               d_v,\n",
        "                                               dropout=dropout)\n",
        "            self.pos_ffn = PositionwiseFeedForward(d_model,\n",
        "                                                   d_inner,\n",
        "                                                   dropout=dropout)\n",
        "\n",
        "        def forward(self, enc_input, slf_attn_mask=None):\n",
        "            enc_output, enc_slf_attn = self.slf_attn(enc_input,\n",
        "                                                     enc_input,\n",
        "                                                     enc_input,\n",
        "                                                     mask=slf_attn_mask)\n",
        "            enc_output = self.pos_ffn(enc_output)\n",
        "\n",
        "            return enc_output, enc_slf_attn\n",
        "\n",
        "\n",
        "    class Encoder(nn.Module):\n",
        "        ''' A encoder model with self attention mechanism. '''\n",
        "        def __init__(\n",
        "            self,\n",
        "            n_src_vocab,\n",
        "            d_word_vec,\n",
        "            n_layers,\n",
        "            n_head,\n",
        "            d_k,\n",
        "            d_v,\n",
        "            d_model,\n",
        "            d_inner,\n",
        "            dropout=0.1,\n",
        "            n_position=89,\n",
        "            scale_emb=False,\n",
        "        ):\n",
        "\n",
        "            super().__init__()\n",
        "\n",
        "            self.src_emb = nn.Linear(in_features=n_src_vocab,\n",
        "                                     out_features=d_word_vec)\n",
        "            self.position_enc = PositionalEncoding(d_word_vec,\n",
        "                                                   n_position=n_position)\n",
        "            self.dropout = nn.Dropout(p=dropout)\n",
        "            self.layer_stack = nn.ModuleList([\n",
        "                EncoderLayer(d_model, d_inner, n_head, d_k, d_v, dropout=dropout)\n",
        "                for _ in range(n_layers)\n",
        "            ])\n",
        "            self.layer_norm = nn.LayerNorm(d_model, eps=1e-6)\n",
        "            self.scale_emb = scale_emb\n",
        "            self.d_model = d_model\n",
        "\n",
        "        def forward(self, src_seq, return_attns=False):\n",
        "\n",
        "            enc_slf_attn_list = []\n",
        "\n",
        "            # -- Forward\n",
        "            enc_output = self.src_emb(src_seq)\n",
        "            if self.scale_emb:\n",
        "                enc_output *= self.d_model**0.5\n",
        "            enc_output = self.dropout(self.position_enc(enc_output))\n",
        "            enc_output = self.layer_norm(enc_output)\n",
        "\n",
        "            for enc_layer in self.layer_stack:\n",
        "                enc_output, enc_slf_attn = enc_layer(enc_output)\n",
        "                enc_slf_attn_list += [enc_slf_attn] if return_attns else []\n",
        "\n",
        "            if return_attns:\n",
        "                return enc_output, enc_slf_attn_list\n",
        "\n",
        "            return enc_output\n",
        "\n",
        "\n",
        "    class Transformer_encoder_model(nn.Module):\n",
        "        def __init__(\n",
        "            self,\n",
        "            n_src_vocab,\n",
        "            d_word_vec,\n",
        "            n_layers,\n",
        "            n_head,\n",
        "            d_k,\n",
        "            d_v,\n",
        "            d_model,\n",
        "            d_inner,\n",
        "            output_class_num,\n",
        "        ):\n",
        "            super().__init__()\n",
        "            self.encoder = Encoder(n_src_vocab, d_word_vec, n_layers, n_head, d_k,\n",
        "                                   d_v, d_model, d_inner)\n",
        "            self.fc1 = nn.Linear(in_features=89 * 128, out_features=output_class_num*4)\n",
        "            self.fc2 = nn.Linear(in_features=output_class_num*4, out_features=output_class_num)\n",
        "\n",
        "        def forward(self, encoder_input, return_attns=False):\n",
        "            output = self.encoder(encoder_input)\n",
        "            output = self.fc1(output.view(output.size(0), -1))\n",
        "            output = self.fc2(output)\n",
        "\n",
        "            return output\n",
        "\n",
        "\n",
        "    MODEL = Transformer_encoder_model(\n",
        "        n_src_vocab=HAI_DATASET_TRAIN[0]['given'].shape[-1],\n",
        "        d_word_vec=128,\n",
        "        n_layers=3,\n",
        "        n_head=4,\n",
        "        d_k=32,\n",
        "        d_v=32,\n",
        "        d_model=128,\n",
        "        d_inner=256,\n",
        "        output_class_num=TRAIN_DF.shape[1]  # class 개수\n",
        "    ).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ac0CJMVsKDO5"
      },
      "source": [
        "## 4_Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "code_folding": [
          5
        ],
        "id": "SXnCR636KDO6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "fe4ba20e579f4b7bbcdac206fcc7286b",
            "c073fab003fb4dcd96002450b1ec9b1c",
            "c7e8a1118cfe44eda0e412d2bc845113",
            "68f1be79196c496b811478cf670a344f",
            "2d1dbb4467bd4b98979656e037515e53",
            "8ffc75efeed64210872181c6773682ae",
            "4483733f3cab46ec8e8dacf7f996798b",
            "d5b9d025cd6f4d4c9bd1f5f6b04e82ca",
            "54d7e7cdb03f4ef79755e85c9c3a0fe4",
            "da91c4134bb246a787c8779f451e3ee6",
            "8c1945920437463a9fc9cb71b5e999e8"
          ]
        },
        "outputId": "6c4bb2db-a28b-467b-fa97-ec81911654b6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "training:   0%|          | 0/20 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe4ba20e579f4b7bbcdac206fcc7286b"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "%%time\n",
        "# loss: MSE\n",
        "# optimizer: damW\n",
        "# save best model\n",
        "\n",
        "def train(dataset, model, batch_size, n_epochs):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "    optimizer = torch.optim.AdamW(model.parameters())\n",
        "    lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.997)  # 3등 코드\n",
        "    loss_fn = torch.nn.MSELoss()\n",
        "#     loss_fn = torch.nn.L1Loss()  # 1등 코드\n",
        "\n",
        "    epochs = trange(n_epochs, desc=\"training\")\n",
        "    best = {\"loss\": sys.float_info.max}\n",
        "    loss_history = []\n",
        "    for e in epochs:\n",
        "        epoch_loss = 0\n",
        "        for batch in dataloader:\n",
        "            optimizer.zero_grad()\n",
        "            given = batch[\"given\"].cuda()\n",
        "            guess = model(given)\n",
        "            answer = batch[\"answer\"].cuda()\n",
        "            loss = loss_fn(answer, guess)\n",
        "            loss.backward()\n",
        "            epoch_loss += loss.item()\n",
        "            optimizer.step()\n",
        "            lr_scheduler.step()\n",
        "        loss_history.append(epoch_loss)\n",
        "        epochs.set_postfix_str(f\"loss: {epoch_loss:.6f}\")\n",
        "        if epoch_loss < best[\"loss\"]:\n",
        "            best[\"state\"] = model.state_dict()\n",
        "            best[\"loss\"] = epoch_loss\n",
        "            best[\"epoch\"] = e + 1\n",
        "    \n",
        "    model.eval()    \n",
        "    print('best model loss&epoch', best[\"loss\"], best[\"epoch\"])\n",
        "    # save\n",
        "    with open(\"model.pt\", \"wb\") as f:\n",
        "        torch.save({\"state\": best[\"state\"],\n",
        "                    \"best_epoch\": best[\"epoch\"],\n",
        "                    \"loss_history\": loss_history}, f)            \n",
        "\n",
        "    return best, loss_history\n",
        "\n",
        "BEST_MODEL, LOSS_HISTORY = train(HAI_DATASET_TRAIN, MODEL, batch_size, epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tn2C-s2tKDO6"
      },
      "source": [
        "## 5_Load trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "code_folding": [
          0
        ],
        "id": "-PDlQ77kKDO6"
      },
      "outputs": [],
      "source": [
        "## load\n",
        "with open('model.pt', 'rb') as f:\n",
        "    SAVED_MODEL = torch.load(f)\n",
        "\n",
        "MODEL.load_state_dict(SAVED_MODEL['state'])\n",
        "\n",
        "plt.figure(figsize=(16, 4))\n",
        "plt.title(\"Training Loss Graph\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.yscale(\"log\")\n",
        "plt.plot(SAVED_MODEL[\"loss_history\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "code_folding": [
          2
        ],
        "id": "BMPUQUDWKDO6"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# inference 함수는 데이터를 순차적으로 보면서 모델이 예측한 값과 실제 값의 차를 구해서 기록\n",
        "def inference(dataset, model, batch_size):\n",
        "    \n",
        "    model.eval()\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size)\n",
        "    ts, dist, att = [], [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            given = batch[\"given\"].cuda()\n",
        "            answer = batch[\"answer\"].cuda()\n",
        "            guess = model(given)\n",
        "            ts.append(np.array(batch[\"ts\"]))\n",
        "            dist.append(torch.abs(answer - guess).cpu().numpy())\n",
        "            try:\n",
        "                att.append(np.array(batch[\"attack\"]))\n",
        "            except:\n",
        "                att.append(np.zeros(batch_size))\n",
        "            \n",
        "    return (np.concatenate(ts), np.concatenate(dist), np.concatenate(att))\n",
        "\n",
        "CHECK_TS, CHECK_DIST, CHECK_ATT = inference(HAI_DATASET_VALIDATION, MODEL, batch_size)\n",
        "\n",
        "# 검증 데이터셋 전체 시간대에 대해 모든 필드의 |예측값 - 실제값|\n",
        "print('CHECK_DIST shape:', CHECK_DIST.shape)\n",
        "# 공격 여부 판단을 위해 같은 시각에서 전체 필드가 산출하는 차의 평균을 계산\n",
        "ANOMALY_SCORE = np.mean(CHECK_DIST, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "code_folding": [
          0
        ],
        "id": "mN6NfqSuKDO7"
      },
      "outputs": [],
      "source": [
        "# ## 3등 솔루션\n",
        "# # anomaly score median filter 정의\n",
        "# def moving_median(x, n= 10):\n",
        "#     a = []\n",
        "#     for i in range(n):\n",
        "#         a.append(np.concatenate([x[i:].copy(), np.zeros([i])]))\n",
        "#     median_ANOMALY_SCORE = np.stack(a)\n",
        "#     median_ANOMALY_SCORE.sort(0)\n",
        "#     # data leakage를 방지하기 위해 n만큼 shift해서 반환\n",
        "#     return np.concatenate([np.zeros([n]), median_ANOMALY_SCORE[n//2][:-n]])\n",
        "\n",
        "# # data leakage 방지를 위해 이전 데이터에 대해서만 moving median 계산\n",
        "# # 최종 anomaly score (median_ANOMALY_SCORE)\n",
        "# FILTER_SIZE = 5\n",
        "# median_ANOMALY_SCORE = moving_median(ANOMALY_SCORE, n= FILTER_SIZE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "code_folding": [
          0
        ],
        "id": "ylAqwYxtKDO7"
      },
      "outputs": [],
      "source": [
        "# from transformer solution, https://dacon.io/competitions/official/235757/codeshare/3244?page=1&dtype=recent\n",
        "def range_check(series, size):\n",
        "    data = []\n",
        "    \n",
        "    for idx in range(size-1):\n",
        "        data.append(series[idx])\n",
        "\n",
        "    for i in range(size, len(series)+1):\n",
        "        if i == size :\n",
        "            check_std = np.std(series[i-size:i])\n",
        "        std = np.std(series[i-size:i])\n",
        "        mean = np.mean(series[i-size:i])\n",
        "        max = np.max(series[i-size:i])\n",
        "        check_std\n",
        "        if check_std * 2 >= std:\n",
        "            check_std = std\n",
        "            data.append(mean)\n",
        "        elif max == series[i]:\n",
        "            data.append(max*5)\n",
        "            check_std = std\n",
        "        else:\n",
        "            data.append(series[i]*3)\n",
        "    #for _ in range(size-1):\n",
        "    #    data.append(mean)\n",
        "\n",
        "    return np.array(data)    \n",
        "    \n",
        "    \n",
        "\n",
        "ANOMALY_SCORE = np.mean(CHECK_DIST, axis=1)\n",
        "C_ANOMALY_SCORE = range_check(ANOMALY_SCORE, size=30)\n",
        "print(C_ANOMALY_SCORE.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "code_folding": [
          3
        ],
        "id": "qv-fD2DIKDO7"
      },
      "outputs": [],
      "source": [
        "## 결과 확인\n",
        "# 주황색 선은 공격 위치를 나타내고, 파란색 선은 (평균) 오차의 크기를 나타냅니다. 전반적으로 공격 위치에서 큰 오차\n",
        "# piece: 그래프를 몇개로 나누어 그릴지\n",
        "def check_graph(xs, att, piece=2, THRESHOLD=None):\n",
        "    l = xs.shape[0]\n",
        "    chunk = l // piece\n",
        "    fig, axs = plt.subplots(piece, figsize=(20, 4 * piece))\n",
        "    for i in range(piece):\n",
        "        L = i * chunk\n",
        "        R = min(L + chunk, l)\n",
        "        xticks = range(L, R)\n",
        "        axs[i].plot(xticks, xs[L:R])\n",
        "        if len(xs[L:R]) > 0:\n",
        "            peak = max(xs[L:R])\n",
        "            axs[i].plot(xticks, att[L:R] * peak * 0.3)\n",
        "        if THRESHOLD!=None:\n",
        "            axs[i].axhline(y=THRESHOLD, color='r')\n",
        "    plt.show()\n",
        "    \n",
        "\n",
        "THRESHOLD = 0.026\n",
        "check_graph(ANOMALY_SCORE, CHECK_ATT, piece=2, THRESHOLD=THRESHOLD)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VL6anKrKDO7"
      },
      "outputs": [],
      "source": [
        "## threshold로 공격 검출\n",
        "# 대략 0.022를 기준으로 설정\n",
        "# 여러 번의 실험을 통해 정밀하게 임계치를 선택\n",
        "# 임의의 threshold(빨간색 선)가 넘어갈 경우 공격으로 간주합니다. 공격은 1로 정상은 0으로 표기\n",
        "def put_labels(distance, threshold):\n",
        "    xs = np.zeros_like(distance)\n",
        "    xs[distance > threshold] = 1\n",
        "    return xs\n",
        "\n",
        "LABELS = put_labels(ANOMALY_SCORE, THRESHOLD)\n",
        "print(LABELS, LABELS.shape)\n",
        "\n",
        "# 정답지(ATTACK_LABELS)도 동일하게 추출, 검증 데이터셋에 공격 여부를 나타내는 필드에는 정상을 0으로 공격을 1로 표기\n",
        "# 0.5를 기준으로 같은 방식으로 TaPR을 위한 label\n",
        "ATTACK_LABELS = put_labels(np.array(VALIDATION_DF_RAW[ATTACK_FIELD]), threshold=0.5)\n",
        "print(ATTACK_LABELS, ATTACK_LABELS.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "code_folding": [
          0,
          17
        ],
        "id": "TE-GY_REKDO7"
      },
      "outputs": [],
      "source": [
        "## 결과 정리\n",
        "'''\n",
        "탐지 모델이 윈도우 방식으로 판단을 진행했기 때문에,\n",
        "1. 첫 시작의 몇 초는 판단을 내릴 수 없고\n",
        "2. 데이터셋 중간에 시간이 연속되지 않는 구간에 대해서는 판단을 내릴 수 없습니다.\n",
        "\n",
        "위에서 보시는 바와 같이 정답에 비해 얻어낸 label의 수가 적습니다.\n",
        "\n",
        "아래의 fill_blank 함수는 빈칸을 채워줍니다.\n",
        "빈 곳은 정상(0) 표기하고 나머지는 모델의 판단(정상 0, 비정상 1)을 채워줍니다.\n",
        "'''\n",
        "\n",
        "def fill_blank(check_ts, labels, total_ts):\n",
        "    def ts_generator():\n",
        "        for t in total_ts:\n",
        "            yield dateutil.parser.parse(t)\n",
        "\n",
        "    def label_generator():\n",
        "        for t, label in zip(check_ts, labels):\n",
        "            yield dateutil.parser.parse(t), label\n",
        "\n",
        "    g_ts = ts_generator()\n",
        "    g_label = label_generator()\n",
        "    final_labels = []\n",
        "\n",
        "    try:\n",
        "        current = next(g_ts)\n",
        "        ts_label, label = next(g_label)\n",
        "        while True:\n",
        "            if current > ts_label:\n",
        "                ts_label, label = next(g_label)\n",
        "                continue\n",
        "            elif current < ts_label:\n",
        "                final_labels.append(0)\n",
        "                current = next(g_ts)\n",
        "                continue\n",
        "            final_labels.append(label)\n",
        "            current = next(g_ts)\n",
        "            ts_label, label = next(g_label)\n",
        "    except StopIteration:\n",
        "        return np.array(final_labels, dtype=np.int8)\n",
        "    \n",
        "FINAL_LABELS = fill_blank(CHECK_TS, LABELS, np.array(VALIDATION_DF_RAW[TIMESTAMP_FIELD]))\n",
        "print(FINAL_LABELS.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dCN7nHEKDO7"
      },
      "source": [
        "## 6_Evaluation\n",
        "\n",
        "평가 metric은 TaPR을 사용\n",
        "정답(ATTACK_LABELS)과 모델의 결과(FINAL_LABELS)의 길이가 같은지 확인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GM6-0B36KDO7"
      },
      "outputs": [],
      "source": [
        "TaPR = etapr.evaluate_haicon(anomalies=ATTACK_LABELS, predictions=FINAL_LABELS)\n",
        "print(f\"F1: {TaPR['f1']:.3f} (TaP: {TaPR['TaP']:.3f}, TaR: {TaPR['TaR']:.3f})\")\n",
        "print(f\"# of detected anomalies: {len(TaPR['Detected_Anomalies'])}\")\n",
        "print(f\"Detected anomalies: {TaPR['Detected_Anomalies']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RFe9WjjYKDO8"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# inference 함수로 데이터를 순차적으로 보면서 모델이 예측한 값과 실제 값의 차를 구해서 기록\n",
        "CHECK_TS, CHECK_DIST, CHECK_ATT = inference(HAI_DATASET_TEST, MODEL, batch_size)\n",
        "\n",
        "# 공격 여부 판단을 위해 같은 시각에서 전체 필드가 산출하는 차의 평균을 계\n",
        "ANOMALY_SCORE = np.mean(CHECK_DIST, axis=1)\n",
        "# 결과를 눈으로 확인하기 위해 그래프\n",
        "check_graph(ANOMALY_SCORE, CHECK_ATT, piece=3, THRESHOLD=THRESHOLD)\n",
        "# 검증 데이터셋을 이용해 찾은 threshold를 이용해 공격 여부를 예측\n",
        "LABELS = put_labels(ANOMALY_SCORE, THRESHOLD)\n",
        "print(LABELS, LABELS.shape)\n",
        "\n",
        "# 예측한 결과를 제출양식에 맞춰 저장\n",
        "submission = pd.read_csv('data/sample_submission.csv')\n",
        "submission.index = submission['timestamp']\n",
        "submission.loc[CHECK_TS,'attack'] = LABELS\n",
        "submission.to_csv('baseline.csv', index=False)\n",
        "submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "id": "J16jKYfhKDO8"
      },
      "source": [
        "## 7_수상 솔루션!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "code_folding": [],
        "hidden": true,
        "id": "5uhXtlc2KDO8"
      },
      "source": [
        "#####  1등 solution, [url](https://dacon.io/competitions/official/235624/codeshare/1830?page=1&dtype=recent)\n",
        "- WINDDOW 사이즈가 각각 다른 9개의 모델을 각각 만든다\n",
        "- 9개중 한 모델이라도 이상을 탐지하면 비정상으로 분류\n",
        "\n",
        "```\n",
        "def Cross_put_labels(Inverse1, Inverse2, Inverse3, Inverse4, Inverse5, Inverse6, Inverse7, Inverse8, Inverse9):\n",
        "    xs = np.zeros_like(Inverse1)\n",
        "    for i in range(Inverse1.shape[0]):\n",
        "        if Inverse1[i] + Inverse2[i] + Inverse3[i] + Inverse4[i] + Inverse5[i] + Inverse6[i] + Inverse7[i] + Inverse8[i] + Inverse9[i] > 0:\n",
        "            xs[i] = 1\n",
        "        else:\n",
        "            xs[i] = 0\n",
        "    return xs\n",
        "\n",
        "################################################################################\n",
        "Cross_LABELS = Cross_put_labels(Final_LABELS1, Final_LABELS2, Final_LABELS3, Final_LABELS4, Final_LABELS5, Final_LABELS6, Final_LABELS7, Final_LABELS8, Final_LABELS9)\n",
        "#check_graph(Cross_LABELS, CHECK_ATT5, piece=2)\n",
        "\n",
        "submission = pd.read_csv('data/HAI 2.0/sample_submission.csv') # ------------------ Check\n",
        "submission.index = submission['time']\n",
        "submission.loc[TEST_DF_RAW[TIMESTAMP_FIELD],'attack'] = Cross_LABELS\n",
        "submission\n",
        "submission.to_csv(\"output(Create_submit)/Final_Cross_baseline(nine parallel).csv\", index=False) # ------------------ Check\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "heading_collapsed": true,
        "hidden": true,
        "id": "SbmMjXCfKDO8"
      },
      "source": [
        "##### 2등 solution, [url](https://dacon.io/competitions/official/235624/codeshare/1831?page=1&dtype=recent)\n",
        "- keras, Bidirectional lstm 3층\n",
        "- WINDOW 10짜리와 60짜리를 조합\n",
        "- Gray Area Smoothing, moving average를 적절히 사용\n",
        "\n",
        "```\n",
        "def Gray_Area(attacks):\n",
        "    start = []  # start point\n",
        "    finish = []  # finish point\n",
        "    c = []  # count\n",
        "    com = 0\n",
        "    count = 0\n",
        "    for i in range(1, len(attacks)):\n",
        "        if attacks[i - 1] != attacks[i]:\n",
        "            if com == 0:\n",
        "                start.append(i)\n",
        "                count = count + 1\n",
        "                com = 1\n",
        "            elif com == 1:\n",
        "                finish.append(i - 1)\n",
        "                c.append(count)\n",
        "                count = 0\n",
        "                start.append(i)\n",
        "                count = count + 1\n",
        "        else:\n",
        "            count = count + 1\n",
        "\n",
        "    finish.append(len(attacks) - 1)\n",
        "    c.append(finish[len(finish) - 1] - start[len(start) - 1] + 1)\n",
        "\n",
        "    for i in range(0, len(start)):\n",
        "        if c[i] < 10:\n",
        "            s = start[i]\n",
        "            f = finish[i] + 1\n",
        "            g1 = [1 for i in range(c[i])] # Temp Attack list\n",
        "            g0 = [0 for i in range(c[i])]  # Temp Normal List\n",
        "            if attacks[start[i] - 1] == 1:\n",
        "                attacks[s:f] = g1  # change to attack\n",
        "            else:\n",
        "                attacks[s:f] = g0  # change to normal\n",
        "\n",
        "    return attacks\n",
        "\n",
        "gray_LABELS_60seq=Gray_Area(LABELS_60seq)\n",
        "\n",
        "\n",
        "\n",
        "## MOVING AVERAGE\n",
        "seq60_10mean=[]\n",
        "for idx in range(len(ANOMALY_SCORE)):\n",
        "    if idx >= 10:\n",
        "        seq60_10mean.append((ANOMALY_SCORE[idx-10:idx].mean()+ANOMALY_SCORE[idx])/2)\n",
        "    else:\n",
        "        seq60_10mean.append(ANOMALY_SCORE[idx])\n",
        "\n",
        "seq60_10mean=np.array(seq60_10mean)\n",
        "print(seq60_10mean.shape)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "hidden": true,
        "id": "--YAdYBOKDO8"
      },
      "source": [
        "##### 3등 solution [url](https://dacon.io/competitions/official/235624/codeshare/1832?page=1&dtype=recent)\n",
        "- 예측 결과에 moving average\n",
        "- WINDOW size는 그대로 90\n",
        "- 모델에 batch_normalization과 Relu non linear func 사용\n",
        "```\n",
        "out = F.relu(self.bn(outs[:, -1]))\n",
        "out = self.fc(out)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "hidden": true,
        "id": "nN0SBEttKDO8"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "Timeseries_Anomaly_Detection_Transformer_colab.ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "39014eae9e4049db97108ba1b4fda192": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f76e4243c59a475996199d9b2c507439",
              "IPY_MODEL_f08672a400fa4504a92a71b0e04de914",
              "IPY_MODEL_bc2a9fe91e304c72a394ac2592a58115"
            ],
            "layout": "IPY_MODEL_71f44c75b7c64ee7aba3c5f8dbd9ec28"
          }
        },
        "f76e4243c59a475996199d9b2c507439": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1aee9ab1cc5c4049820bcc39500129b6",
            "placeholder": "​",
            "style": "IPY_MODEL_8853b2ba36ee415a8d77a6291465dc21",
            "value": "100%"
          }
        },
        "f08672a400fa4504a92a71b0e04de914": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8df8722607c34b458dfac93b19ab5b1e",
            "max": 1004313,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_05d9f80811cc4b1ea65511da79085114",
            "value": 1004313
          }
        },
        "bc2a9fe91e304c72a394ac2592a58115": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0aba92e4fc634ecb8b0589aec8207b9b",
            "placeholder": "​",
            "style": "IPY_MODEL_b82bdc93b05546548a6ad9b97778a413",
            "value": " 1004313/1004313 [03:30&lt;00:00, 5331.07it/s]"
          }
        },
        "71f44c75b7c64ee7aba3c5f8dbd9ec28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1aee9ab1cc5c4049820bcc39500129b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8853b2ba36ee415a8d77a6291465dc21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8df8722607c34b458dfac93b19ab5b1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05d9f80811cc4b1ea65511da79085114": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0aba92e4fc634ecb8b0589aec8207b9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b82bdc93b05546548a6ad9b97778a413": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1bf774806ae2426289c48990c02d5e78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bf00b2f646cb4782ba97e06aaba39c01",
              "IPY_MODEL_672ff02a463c4175b1d6d502f1ac0359",
              "IPY_MODEL_9f71b8fcf1084ddf9e3afb8c9bb97ecb"
            ],
            "layout": "IPY_MODEL_7f07539d85174051a06b2008f975cc08"
          }
        },
        "bf00b2f646cb4782ba97e06aaba39c01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28230cba99d5460788564eec3933c834",
            "placeholder": "​",
            "style": "IPY_MODEL_174d06a91040448f85a618eb9608b799",
            "value": "100%"
          }
        },
        "672ff02a463c4175b1d6d502f1ac0359": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34160db8fca04a88bbdda12c9070d315",
            "max": 86311,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7abd9f5ec69049c7a056626846cd65a7",
            "value": 86311
          }
        },
        "9f71b8fcf1084ddf9e3afb8c9bb97ecb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6d07f190965493c9240936491f2c900",
            "placeholder": "​",
            "style": "IPY_MODEL_29aeddc801a347d7959763a6ae6a95b3",
            "value": " 86311/86311 [00:16&lt;00:00, 5387.80it/s]"
          }
        },
        "7f07539d85174051a06b2008f975cc08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28230cba99d5460788564eec3933c834": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "174d06a91040448f85a618eb9608b799": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34160db8fca04a88bbdda12c9070d315": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7abd9f5ec69049c7a056626846cd65a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e6d07f190965493c9240936491f2c900": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29aeddc801a347d7959763a6ae6a95b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad5d5cddacd4494da179f1692018de3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6eec3560d9a042c6807e2b5beb471314",
              "IPY_MODEL_34a47072f70e4a55b1e0f0899d931075",
              "IPY_MODEL_60cb0565162f41d8982ac73be9c95b6d"
            ],
            "layout": "IPY_MODEL_465813650760485481e629babf6b34b3"
          }
        },
        "6eec3560d9a042c6807e2b5beb471314": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8573d07596c84c9680ac3cae6b381519",
            "placeholder": "​",
            "style": "IPY_MODEL_339b65949b874f9a91c33f8ab168191a",
            "value": "100%"
          }
        },
        "34a47072f70e4a55b1e0f0899d931075": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_109eda945e0742dba2406cfea225a5dd",
            "max": 274711,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_964ec628a78b47738afada32617fdec8",
            "value": 274711
          }
        },
        "60cb0565162f41d8982ac73be9c95b6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7951da553a84daf999fc2a0058fea32",
            "placeholder": "​",
            "style": "IPY_MODEL_586ec79202b4450c814d8493e8d3c079",
            "value": " 274711/274711 [00:52&lt;00:00, 5511.69it/s]"
          }
        },
        "465813650760485481e629babf6b34b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8573d07596c84c9680ac3cae6b381519": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "339b65949b874f9a91c33f8ab168191a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "109eda945e0742dba2406cfea225a5dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "964ec628a78b47738afada32617fdec8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d7951da553a84daf999fc2a0058fea32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "586ec79202b4450c814d8493e8d3c079": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe4ba20e579f4b7bbcdac206fcc7286b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c073fab003fb4dcd96002450b1ec9b1c",
              "IPY_MODEL_c7e8a1118cfe44eda0e412d2bc845113",
              "IPY_MODEL_68f1be79196c496b811478cf670a344f"
            ],
            "layout": "IPY_MODEL_2d1dbb4467bd4b98979656e037515e53"
          }
        },
        "c073fab003fb4dcd96002450b1ec9b1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ffc75efeed64210872181c6773682ae",
            "placeholder": "​",
            "style": "IPY_MODEL_4483733f3cab46ec8e8dacf7f996798b",
            "value": "training:  25%"
          }
        },
        "c7e8a1118cfe44eda0e412d2bc845113": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5b9d025cd6f4d4c9bd1f5f6b04e82ca",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_54d7e7cdb03f4ef79755e85c9c3a0fe4",
            "value": 5
          }
        },
        "68f1be79196c496b811478cf670a344f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da91c4134bb246a787c8779f451e3ee6",
            "placeholder": "​",
            "style": "IPY_MODEL_8c1945920437463a9fc9cb71b5e999e8",
            "value": " 5/20 [03:51&lt;11:34, 46.27s/it, loss: 1.767881]"
          }
        },
        "2d1dbb4467bd4b98979656e037515e53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ffc75efeed64210872181c6773682ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4483733f3cab46ec8e8dacf7f996798b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d5b9d025cd6f4d4c9bd1f5f6b04e82ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54d7e7cdb03f4ef79755e85c9c3a0fe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "da91c4134bb246a787c8779f451e3ee6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c1945920437463a9fc9cb71b5e999e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}